{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBL9GuvWmKZx"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/minsuk-heo/tf2/blob/master/jupyter_notebooks/08.RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qebi4ZenmKZ2"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "RodJKvqhmKZ7"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "try:\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xBTOLsTXmKZ-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, SimpleRNN, TimeDistributed\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPawpjjamKaA"
   },
   "source": [
    "# RNN Cell Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ASsREjRxmKaB"
   },
   "outputs": [],
   "source": [
    "# input shape\n",
    "inputs = Input(shape=(1,2))\n",
    "# output shape, return state, use tanh as activation function\n",
    "output, state = SimpleRNN(3, return_state=True, activation='tanh')(inputs)\n",
    "model = Model(inputs=inputs, outputs=[output, state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7ysf5z33mKaD",
    "outputId": "6ffb057a-579e-451e-9c58-1ff76323fe64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output:  [[ 0.9535143 -0.7490182 -0.9900427]]\n",
      "state:  [[ 0.9535143 -0.7490182 -0.9900427]]\n"
     ]
    }
   ],
   "source": [
    "# test input\n",
    "data = np.array([[ [1,2] ]])\n",
    "# print output, state\n",
    "output, state = model.predict(data)\n",
    "print(\"output: \",output)\n",
    "print(\"state: \",state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "UEOLvJ5DmKaG",
    "outputId": "ae3d5b59-0f72-49f8-d365-cf4e541a8da5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'simple_rnn/kernel:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 0.6104852 , -0.54800415, -0.7335443 ],\n",
       "       [ 0.62931764, -0.21135521, -0.9576273 ]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights for input\n",
    "model.layers[1].weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "MI_pQIitmKaI",
    "outputId": "2d437db4-996f-4b65-8565-36bb2cb07608"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'simple_rnn/recurrent_kernel:0' shape=(3, 3) dtype=float32, numpy=\n",
       "array([[ 0.44253075,  0.82417303, -0.35341927],\n",
       "       [-0.8753928 ,  0.48253262,  0.02914993],\n",
       "       [-0.19456093, -0.29648095, -0.93501073]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weights for state\n",
    "model.layers[1].weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ST7Hy9XhmKaL",
    "outputId": "dacbdc56-06c0-4f41-ef9f-f6987c05cbfb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'simple_rnn/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bias\n",
    "model.layers[1].weights[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GV6uspykmKaO"
   },
   "source": [
    "# sequence tagging example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "t7-_eGt1mKaP"
   },
   "outputs": [],
   "source": [
    "John = [1,0,0]\n",
    "loves = [0,1,0]\n",
    "Jane = [0,0,1]\n",
    "\n",
    "X = np.array([\n",
    "    [ John, loves, Jane ],\n",
    "    [ Jane, loves, John ]\n",
    "]).astype(np.float32)\n",
    "\n",
    "S = [0] # subject\n",
    "V = [1] # verb\n",
    "O = [2] # object\n",
    "y = np.array([[S, V, O], [S, V, O]]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4MZcEyAFmKaR"
   },
   "outputs": [],
   "source": [
    "# input shape\n",
    "inputs = Input(shape=(3, 3))\n",
    "# output shape, return state, return sequence\n",
    "output, state = SimpleRNN(3, return_state=True, return_sequences=True)(inputs)\n",
    "model = Model(inputs=inputs, outputs=[output, state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "e0Jhv-eZmKaT"
   },
   "outputs": [],
   "source": [
    "# print output, state\n",
    "output, state = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_vCIwvIfmKaV",
    "outputId": "2cfcc109-3187-4dbd-b71f-1676d9cf940d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John loves Jane:  [[-0.4554843  -0.28991818  0.29535207]\n",
      " [-0.16001493  0.3908994  -0.5016279 ]\n",
      " [ 0.46448052  0.2849049   0.08927286]]\n",
      "Jane loves John:  [[ 0.13979295  0.65092736 -0.16323304]\n",
      " [ 0.00874742 -0.6103008  -0.7412528 ]\n",
      " [ 0.37680146  0.06187805  0.23907773]]\n"
     ]
    }
   ],
   "source": [
    "print(\"John loves Jane: \",output[0])\n",
    "print(\"Jane loves John: \",output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GRJgQxzCmKaX",
    "outputId": "26d0ac30-6a20-4e7f-a028-1b6e47b4c5d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John loves Jane: state:  [0.46448052 0.2849049  0.08927286]\n",
      "Jane loves John: state:  [0.37680146 0.06187805 0.23907773]\n"
     ]
    }
   ],
   "source": [
    "# the state value is same with the last output\n",
    "print(\"John loves Jane: state: \",state[0])\n",
    "print(\"Jane loves John: state: \",state[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ni2tXs3lmKab",
    "outputId": "3f3496fd-40f7-4c60-f6ce-2b3922874d3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 3, 3)              21        \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 3, 3)              12        \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23074519788>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape=(3, 3), return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(3, activation=\"softmax\")))\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())\n",
    "# train, takes 30sec, if you want to monitor progreses, change verbose=1\n",
    "model.fit(X, y, epochs=2000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "11ee8GyumKad"
   },
   "outputs": [],
   "source": [
    "result = model.predict(X, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "xZ5u1TecmKaf",
    "outputId": "e8556898-314c-456c-fdf8-2f7d0fea9803"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [0, 1, 2]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the result\n",
    "\n",
    "# 0 : Subject\n",
    "# 1 : Verb\n",
    "# 2 : Object\n",
    "np.argmax(result, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkByF8S4mKah"
   },
   "source": [
    "# Sentence Classification\n",
    "classify movie review into positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "f-ryyAEXmKah"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "uBB32GZGmKak"
   },
   "outputs": [],
   "source": [
    "movie_reviews = [\n",
    "         {'review': 'this is the best movie', 'sentiment': 'positive'},\n",
    "         {'review': 'i recommend you watch this movie', 'sentiment': 'positive'},\n",
    "         {'review': 'it was waste of money and time', 'sentiment': 'negative'},\n",
    "         {'review': 'the worst movie ever', 'sentiment': 'negative'}\n",
    "    ]\n",
    "df = pd.DataFrame(movie_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "q4HrTvYdmKao",
    "outputId": "49c7d530-fc9a-4171-deb8-4d7a96430eb2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is the best movie</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i recommend you watch this movie</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it was waste of money and time</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the worst movie ever</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review sentiment\n",
       "0            this is the best movie  positive\n",
       "1  i recommend you watch this movie  positive\n",
       "2    it was waste of money and time  negative\n",
       "3              the worst movie ever  negative"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cqvSVYxbmKar"
   },
   "outputs": [],
   "source": [
    "def get_vocab2int(df):\n",
    "    d = {}\n",
    "    vocab = set()\n",
    "    df['review'].str.split().apply(vocab.update)\n",
    "    for idx, word in enumerate(vocab):\n",
    "        d[word] = idx\n",
    "    return d\n",
    "\n",
    "vocab2_int = get_vocab2int(df)\n",
    "vocab_size = len(vocab2_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "P4FvTZnMmKat"
   },
   "outputs": [],
   "source": [
    "# encode words into integer\n",
    "reviews = df['review'].tolist()\n",
    "encoded_reviews = []\n",
    "for review in reviews:\n",
    "    tokens = review.split(\" \")\n",
    "    review_encoding = []\n",
    "    for token in tokens:\n",
    "        review_encoding.append(vocab2_int[token])\n",
    "    encoded_reviews.append(review_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "rSFnKTS2mKaw",
    "outputId": "4b5e03ed-fd2a-4f17-c3e2-4817d5a82457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14, 4, 15, 17, 11]\n",
      "[3, 8, 6, 12, 14, 11]\n",
      "[7, 2, 1, 9, 10, 16, 0]\n",
      "[15, 13, 11, 5]\n"
     ]
    }
   ],
   "source": [
    "# encoded reviews\n",
    "print(encoded_reviews[0])\n",
    "print(encoded_reviews[1])\n",
    "print(encoded_reviews[2])\n",
    "print(encoded_reviews[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HavqXnyomKaz"
   },
   "outputs": [],
   "source": [
    "def get_max_length(df):\n",
    "    max_length = 0\n",
    "    for row in df['review']:\n",
    "        if len(row.split(\" \")) > max_length:\n",
    "            max_length = len(row.split(\" \"))\n",
    "    return max_length\n",
    "\n",
    "# max_length is used for max sequence of input\n",
    "max_length = get_max_length(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "WYF8-IvsmKa1"
   },
   "outputs": [],
   "source": [
    "# if review is short, fill in zero padding and make all sentence length to be same as max_length\n",
    "padded_reviews_encoding = pad_sequences(encoded_reviews, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "wcfx2UuHmKa4"
   },
   "outputs": [],
   "source": [
    "sentiments = df['sentiment'].tolist()\n",
    "def sentiment_encode(sentiment):\n",
    "    if sentiment == 'positive':\n",
    "        return [1,0]\n",
    "    else:\n",
    "        return [0,1]\n",
    "\n",
    "# encoded sentiment\n",
    "encoded_sentiment = [sentiment_encode(sentiment) for sentiment in sentiments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Bmdw6WJumKa6"
   },
   "outputs": [],
   "source": [
    "# RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 3, input_length=max_length))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "a9AFPgh-mKa8"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "T2AAE-_GmKa_"
   },
   "outputs": [],
   "source": [
    "train_X = np.array(padded_reviews_encoding)\n",
    "train_Y = np.array(encoded_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "XmRLQcsamKbB",
    "outputId": "1f9192fc-442e-462d-a3dc-2e43f8b48055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 4 samples\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 1s 259ms/sample - loss: 0.6806 - accuracy: 0.7500\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 745us/sample - loss: 0.6742 - accuracy: 1.0000\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.6680 - accuracy: 1.0000\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 748us/sample - loss: 0.6617 - accuracy: 1.0000\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.6553 - accuracy: 1.0000\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 998us/sample - loss: 0.6487 - accuracy: 1.0000\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 747us/sample - loss: 0.6418 - accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.6344 - accuracy: 1.0000\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 996us/sample - loss: 0.6265 - accuracy: 1.0000\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 748us/sample - loss: 0.6180 - accuracy: 1.0000\n",
      "Epoch 11/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.6088 - accuracy: 1.0000\n",
      "Epoch 12/50\n",
      "4/4 [==============================] - 0s 747us/sample - loss: 0.5988 - accuracy: 1.0000\n",
      "Epoch 13/50\n",
      "4/4 [==============================] - 0s 995us/sample - loss: 0.5880 - accuracy: 1.0000\n",
      "Epoch 14/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5763 - accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.5636 - accuracy: 1.0000\n",
      "Epoch 16/50\n",
      "4/4 [==============================] - 0s 996us/sample - loss: 0.5500 - accuracy: 1.0000\n",
      "Epoch 17/50\n",
      "4/4 [==============================] - 0s 748us/sample - loss: 0.5352 - accuracy: 1.0000\n",
      "Epoch 18/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.5193 - accuracy: 1.0000\n",
      "Epoch 19/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.5023 - accuracy: 1.0000\n",
      "Epoch 20/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.4841 - accuracy: 1.0000\n",
      "Epoch 21/50\n",
      "4/4 [==============================] - 0s 747us/sample - loss: 0.4646 - accuracy: 1.0000\n",
      "Epoch 22/50\n",
      "4/4 [==============================] - 0s 747us/sample - loss: 0.4440 - accuracy: 1.0000\n",
      "Epoch 23/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.4221 - accuracy: 1.0000\n",
      "Epoch 24/50\n",
      "4/4 [==============================] - 0s 987us/sample - loss: 0.3991 - accuracy: 1.0000\n",
      "Epoch 25/50\n",
      "4/4 [==============================] - 0s 748us/sample - loss: 0.3750 - accuracy: 1.0000\n",
      "Epoch 26/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.3500 - accuracy: 1.0000\n",
      "Epoch 27/50\n",
      "4/4 [==============================] - 0s 747us/sample - loss: 0.3242 - accuracy: 1.0000\n",
      "Epoch 28/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.2978 - accuracy: 1.0000\n",
      "Epoch 29/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.2712 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "4/4 [==============================] - 0s 986us/sample - loss: 0.2445 - accuracy: 1.0000\n",
      "Epoch 31/50\n",
      "4/4 [==============================] - 0s 991us/sample - loss: 0.2182 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.1926 - accuracy: 1.0000\n",
      "Epoch 33/50\n",
      "4/4 [==============================] - 0s 746us/sample - loss: 0.1681 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.1450 - accuracy: 1.0000\n",
      "Epoch 35/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.1237 - accuracy: 1.0000\n",
      "Epoch 36/50\n",
      "4/4 [==============================] - 0s 996us/sample - loss: 0.1044 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.0872 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "4/4 [==============================] - 0s 996us/sample - loss: 0.0722 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0593 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.0485 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "4/4 [==============================] - 0s 996us/sample - loss: 0.0395 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0321 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.0262 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "4/4 [==============================] - 0s 748us/sample - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0145 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "4/4 [==============================] - 0s 997us/sample - loss: 0.0120 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0101 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "4/4 [==============================] - 0s 1ms/sample - loss: 0.0085 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "4/4 [==============================] - 0s 996us/sample - loss: 0.0073 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x230769e85c8>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Train...')\n",
    "model.fit(train_X, train_Y,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "fSa03fDsmKbD",
    "outputId": "9433cb59-e4da-48f3-bcd4-577f80c4864b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/1 - 0s - loss: 0.0063 - accuracy: 1.0000\n",
      "Test score: 0.006257656961679459\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(train_X, train_Y, verbose=2)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "08.RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
